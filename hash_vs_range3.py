import os
from openai import OpenAI
# Initialize OpenAI client with your API key
client = OpenAI(api_key="")  # or use os.getenv("OPENAI_API_KEY")

schema = """
CREATE TABLE hash_vs_range (
   id bigint GENERATED BY DEFAULT AS IDENTITY,
   car varchar,
   speed int,
   ts timestamp,
   PRIMARY KEY(id HASH)
) SPLIT INTO 3 TABLETS;
"""

query = "select * from hash_vs_range where id > 1 and id < 4;"

explain_plan = """
explain (analyze, dist) select * from hash_vs_range where id > 1 and id < 4;
                                                 QUERY PLAN
--------------------------------------------------------------------------------------------
 Seq Scan on hash_vs_range  (cost=0.00..105.00 rows=1000 width=54) (actual time=0.463..0.465 rows=2 loops=1)
   Storage Filter: ((id > 1) AND (id < 4))
   Storage Table Read Requests: 1
   Storage Table Read Execution Time: 0.392 ms
   Storage Table Rows Scanned: 100
 Planning Time: 1.860 ms
 Execution Time: 0.517 ms
 Storage Read Requests: 1
 Storage Read Execution Time: 0.392 ms
 Storage Rows Scanned: 100
 Storage Write Requests: 0
 Catalog Read Requests: 5
 Catalog Read Execution Time: 1.434 ms
 Catalog Write Requests: 0
 Storage Flush Requests: 0
 Storage Execution Time: 1.826 ms
 Peak Memory Usage: 24 kB

"""


context = """
YugabyteDB Query Optimization Context

Partitioning Model:
- YugabyteDB partitions tables into tablets.
- By default, primary keys are HASH partitioned across tablets. This ensures even data distribution but makes range queries and ORDER BY inefficient.
- RANGE partitioning (PRIMARY KEY(id ASC)) stores data in key order, making range queries and ORDER BY efficient, but can cause write hotspots if inserts are sequential.

The Common Query Problem:
- Range predicates (WHERE key BETWEEN ...) or ORDER BY clauses perform poorly on hash-partitioned tables because data is not stored in order.
- Full table scans or full index scans often result, as shown in the explain plan.

soultion 1 

   First propose the simplest Solution: Add Secondary ASC Index
   Example:
   CREATE INDEX my_table_key_idx ON my_table (key ASC);
   - Creating a secondary ASC index allows Yugabyte to satisfy range predicates and ORDER BY queries efficiently, even on hash-partitioned tables.
   - This solution works transparently for most queries without needing query rewrites.
   Drawbacks of Secondary ASC Index:
    1. Write Overhead: Maintaining secondary indexes adds DML cost for INSERT, UPDATE, DELETE operations.
    2. Hotspot Risk: If the indexed column is monotonically increasing (timestamps, IDs), write hotspots may form in the index.

solution 2
   Second propose recreating the table with range sharding instead of the default HASH partitioning
   Uses the supplied table defintion and replce the primary key defintion 
   from   PRIMARY KEY(key) to   PRIMARY KEY(key ASC)
   to provided and example create table statement
   Advantages: avoids maintaining a secondary index. Supports range and order by queries transparently.
   Drawbacks of recreating the table using range partioning:
    1. recreating the table can be challenging on large tables or tables that are heavily used
    2. Hotspot Risk: If the range index column is monotonically increasing (timestamps, IDs), write hotspots may form in the table.

solution 3

    avoid Hotspot with  Secondary Index with Bucket ID

   - Add a virtual bucketing column (e.g., bucket_id) to the secondary index without changing the base table.
   - This spreads inserts across multiple buckets, reducing hotspots.
   - For ORDER BY queries, UNION ALL queries across each bucket are required.
   - The number of buckets should typically be small (3â€“8) to keep UNION queries manageable.
   - Range queries remain fully transparent.

   Example Secondary Index using bucket ID:

      CREATE INDEX buckets_indx ON buckets_ind (
       (yb_hash_code(id) % 3) ASC, id);

    Only queries with Order By need to be rewritten.
    Example of rewriting order by query with index that has bucket ids
    THis rewrite is for order by only and doesn't need to include an range filtering

    SELECT * FROM (
        (SELECT * FROM buckets_ind WHERE (yb_hash_code(id) % 3) = 0 ORDER BY id ASC LIMIT 3) UNION ALL
        (SELECT * FROM buckets_ind WHERE (yb_hash_code(id) % 3) = 1  ORDER BY id ASC LIMIT 3) UNION ALL
        (SELECT * FROM buckets_ind WHERE (yb_hash_code(id) % 3) = 2  ORDER BY id ASC LIMIT 3) UNION ALL
        (SELECT * FROM buckets_ind WHERE (yb_hash_code(id) % 3) = 0  ORDER BY id ASC LIMIT 3)) AS combined
    ORDER BY id ASC
    LIMIT 3;
    
    Advantage: the hash partioned table already has data spread evening. By adding bucketid to the ASC index, the index will also benefit from data being spread evenly.

    Disadvantages:
    Extra overhead for maintaining a secondary index
    Have to rewrite sql using order by in order to take advanage of the secondary index

solution 4
      Avoid Hotspot Workaround by Repartition Base Table with Bucket ID

    - Modify table to add bucket_id directly to primary key: PRIMARY KEY (bucketid ASC, id ASC).
    - This distributes tables tablets 
    - for efficent ORDER BY requires UNION ALL across buckets 
    - Advantage: removes need for secondary indexes entirely.
    - Disadvantage: table needs to be fully rebuilt and reloaded, which can be operationally challenging for large tables or systems requiring continuous uptime.

    CREATE TABLE my_table (
       id bigint GENERATED BY DEFAULT AS IDENTITY, 
       car varchar, 
       speed int,    
       ts timestamp,
       bucketid smallint DEFAULT (random()::smallin % 3), 
       PRIMARY KEY(bucketid ASC, id ASC)
    );

    SELECT * FROM (
        (SELECT * FROM my_table  WHERE bucketid = 0   ORDER BY id ASC   LIMIT 3) UNION ALL
        (SELECT * FROM my_table  WHERE bucketid = 1  ORDER BY id ASC   LIMIT 3) UNION ALL
        (SELECT * FROM my_table  WHERE bucketid = 2  ORDER BY id ASC  LIMIT 3)
    ) AS combined
    ORDER BY id ASC LIMIT 3;


    when given an example of recreating the table define the buckedid feild as exactly "bucketid smallint DEFAULT (random()::smallin % 3)"
    Only queries with Order By need to be rewritten.
    Example of rewriting order by query with index that has bucket ids

    In the example of rewritting the order by, each individual select needs a LIMIT of 3, so that the final LIMIT of 3 is guarenteed to be the top 3


Guidance for for output report:

  - give all for soutions 1, 2, 3 and 4
  - Always output full DDL code snippets for each solution.
  - Clearly explain trade-offs between each approach.
  - Always output full SQL examples for 
    1. example creating secondary index
    2. example recreating table with range partioning
    3. example creating secondary index with bucketid
    4. example of using bucket id and UNION ALL for order by query with secondary index that has bucketid
    5. example creating table with bucketid 
    6. example of writing  ORDER BY queries with UNION all  bucketid  which is slightly different than the UNION ALL example with secondary index

In Summary

   Trade-off Summary:
   - Secondary indexes are the easiest solution and fully transparent to application code, but may impact write throughput.
   - Bucket-based designs reduce hotspots but require more complex query rewrites for ORDER BY.
   - Repartitioning tables may offer best performance but requires table rebuilds and may not be practical for large production systems.
"""


prompt = f"""

You are a postgres performance expert. Here you will be analyzing a postgres comaptibale database Yugabyte.

Please review and optimize the following PostgreSQL sql query based on the schema definition and explain plan.

Here is the query: {query}
Here is the schema of the table: {schema}
Here is the explain plan for the query were are running:  {explain_plan}


{context}

"""

response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a PostgreSQL query tuning expert."},
        {"role": "user", "content": prompt}
    ]
)

print(response.choices[0].message.content)

