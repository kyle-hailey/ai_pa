Report

Your input query:

```sql
SELECT *
FROM customers_tmp c
JOIN orders_tmp o ON c.id = o.customer_id
JOIN products_tmp p ON o.id = p.id
WHERE o.date > '2024-01-15'
  AND p.category = 'Shoes';
```

Problem Detected:

This query uses a range filter on the `date` field of the `orders_tmp` table. The explain plan shows a sequential scan (`Seq Scan`) on this table. This happens because the table is hash-partitioned on the primary key and there isn't an ordered (ASC) index to support efficient data access for range queries.

Proposed Solutions:

Solution 1 - Add Secondary ASC Index

Create a new secondary index on the `date` field of the `orders_tmp` table to optimize range queries:

```sql
CREATE INDEX orders_tmp_date_idx ON orders_tmp (date ASC);
```

This index will allow Postgres to use a quick index scan instead of a slower table scan, significantly improving the performance of range queries. The downside is that maintaining the index can slow down writes and uses additional disk space.

---

Solution 2 - Repartition Table to Range Partitioning

Recreate the `orders_tmp` table with an ASC primary key to optimize the table for range queries:

```sql
CREATE TABLE orders_tmp_v2 (
   id SERIAL PRIMARY KEY,
   customer_id INT REFERENCES customers_tmp(id),
   date DATE,
   PRIMARY KEY (date ASC, id)
) SPLIT INTO N TABLETS;
```

This approach will speed up range queries and ORDER BY operations but may negatively impact write performance if there's a high insert rate with increasing `date`s - i.e., a write hotspot.

---

Solution 3 - Use Secondary Index with Bucket ID

Add a supplementary 'bucketing' field to the secondary index to distribute writes evenly across several 'buckets':

```sql
CREATE INDEX orders_tmp_bucket_idx ON orders_tmp(
  (yb_hash_code(date) % 3) ASC, 
  date ASC
);
```

Queries would need to UNION ALL across buckets:

```sql
SELECT * FROM (
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 0 ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 1 ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 2 ORDER BY date ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
```

This strategy reduces write hotspots while preserving the initial table structure. However, it requires rewriting the query and might add complexity to the application code.

---

Solution 4 - Modify Table Primary Key to Include Bucket ID

Alter the base table schema to include a 'bucketid' directly in the primary key:

```sql
CREATE TABLE orders_tmp_v3 (
   id INT GENERATED BY DEFAULT AS IDENTITY,
   customer_id INT REFERENCES customers_tmp(id),
   date DATE,
   bucketid smallint DEFAULT ((random()*10)::int % 3), 
   PRIMARY KEY (bucketid ASC, date ASC, id)
) SPLIT INTO 3 TABLETS;
```

Queries must be rewritten as:

```sql
SELECT * FROM (
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 0  ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 1 ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 2 ORDER BY date ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
```
This approach reduces write hotspots but requires migrating data to a new table.

---

Conclusion:

Each strategy comes with trade-offs to consider:
- Adding a secondary index can speed up the range queries but slows down write operations and utilizes more storage.
- Partitioning the table improves range query performance but might induce write hotspots.
- Using secondary indexes with buckets and modifying the primary key to include a bucket ID can balance out trade-offs but necessitate query modifications.
