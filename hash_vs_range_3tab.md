Report

Your input query:

```
SELECT *
FROM customers_tmp c
JOIN orders_tmp o ON c.id = o.customer_id
JOIN products_tmp p ON o.id = p.id
WHERE o.date > '2024-01-15'
  AND p.category = 'Shoes';
```

Problem Detected:

The given query uses a range predicate. The explain plan shows sequential scan on the hash-partitioned table "orders_tmp" which is used for date range comparison in the query. As this table doesn't have an supporting ASC index, the query performance might be sub-optimal and can be improved.

Proposed Solutions:

### Solution 1 - Add Secondary ASC Index

We can create an ASC index on the 'date' column of the 'orders_tmp' table in order to enable efficient range scans. 

```SQL
CREATE INDEX orders_tmp_date_idx ON orders_tmp (date ASC);
```

This will allow faster lookups based on 'date' field values and help to improve the range scan performance. However, the added index will increase write costs and might also introduce certain write hotspots if there is a uniformly increasing date pattern in your workload.

---

### Solution 2 - Repartition Table to Range Partitioning

Another solution is to recreate the 'orders_tmp' table with the 'date' column as an ASC primary key to enable data sorting by the date directly.

```SQL
CREATE TABLE orders_tmp_v2 (
   id INT GENERATED BY DEFAULT AS IDENTITY,
   customer_id INT REFERENCES customers_tmp(id),
   date DATE,
   PRIMARY KEY (date ASC)
) SPLIT INTO N TABLETS;
```
This will avoid full scans for date range queries, but may cause write hotspots for sequentially increasing dates. Be warned, redefining large existing tables could present operational challenges.

---

### Solution 3 - Use Secondary Index with Bucket ID

To avoid some of these hotspots on date key while retaining fast lookups, we can add bucketing to the secondary index. 

```SQL
CREATE INDEX orders_tmp_bucket_idx ON orders_tmp (
  (yb_hash_code(date) % 3) ASC, 
  date ASC
);
```

To take advantage of this index, you will have to modify the 'ORDER BY' queries to UNION ALL across the buckets, but regular queries with range predicates can be run without modification.

```SQL
SELECT * FROM (
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 0 ORDER BY id ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 1 ORDER BY id ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 2 ORDER BY id ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
```

---

### Solution 4 - Modify Table Primary Key to Include Bucket ID

If we modify the base table 'orders_tmp' schema to include 'bucketid' directly in the primary key, we can achieve better distribution and efficient range scans.

```SQL
CREATE TABLE orders_tmp_v3 (
   id INT GENERATED BY DEFAULT AS IDENTITY,
   customer_id INT REFERENCES customers_tmp(id),
   date DATE,
   bucketid smallint DEFAULT ((random()*10)::int % 3), 
   PRIMARY KEY (bucketid ASC, date ASC)
) SPLIT INTO 3 TABLETS;
```

Similar to the previous solution, queries with 'ORDER BY' will need to be modified to UNION ALL across buckets and take advantage of efficiencies with the 'bucketid' field.

```SQL
SELECT * FROM (
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 0 ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 1 ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 2 ORDER BY date ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
```

---

Conclusion:

Each of these solutions carry various trade-offs:
- The use of secondary indexes can implicate performance in write-heavy workloads and introduce certain write hotspots.
- While bucketed indexes can avoid these hotspots, it requires rewriting of 'ORDER BY' queries.
- Repartitioning the table is the ideal solution for workloads that mainly involve range queries, however, can require some downtime or extra operations to reload data if the table is large.
