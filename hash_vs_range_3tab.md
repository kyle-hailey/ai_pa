# PostgreSQL Query Optimization Report for YugabyteDB

==============================
Report

## Your input query:

```sql
explain (analyze, dist) SELECT *
FROM customers_tmp c
JOIN orders_tmp o ON c.id = o.customer_id
JOIN products_tmp p ON o.id = p.id
WHERE o.date > '2024-01-15'
 AND p.category = 'Shoes';
Problem Detected:
This query uses a range predicate (o.date > '2024-01-15') and the explain plan shows a sequential scan on the orders_tmp table, which is hash-partitioned without a supporting ASC index on the date column. The sequential scan is scanning 103 rows when potentially fewer rows might match the date filter with proper indexing.
YugabyteDB Partitioning Model:

YugabyteDB partitions tables into tablets.
By default, tables are HASH partitioned on primary keys for even write distribution but inefficient range access.
RANGE partitioning (PRIMARY KEY(field ASC)) keeps rows ordered but may create write hotspots for sequential inserts.

Common query problem:

Queries using range predicates or ORDER BY on hash-partitioned tables often trigger sequential scans, even when only a small key range is needed.
The lack of ordered storage leads to full table scans.

Proposed Solutions:
Solution 1 - Add Secondary ASC Index
Propose creating an ASC index to optimize the query:
sqlCREATE INDEX orders_tmp_date_idx ON orders_tmp (date ASC);
This allows efficient range scans on the date column. Drawbacks include write overhead and potential hotspots on monotonically increasing keys.

Solution 2 - Repartition Table to Range Partitioning
Propose recreating the table with ASC primary key to directly store data ordered by key:
sqlCREATE TABLE orders_tmp_v2 (
   id bigint GENERATED BY DEFAULT AS IDENTITY,
   customer_id INT,
   date DATE,
   PRIMARY KEY (date ASC, id ASC)
) SPLIT INTO 3 TABLETS;

-- Add foreign key constraint
ALTER TABLE orders_tmp_v2 ADD CONSTRAINT fk_customer 
FOREIGN KEY (customer_id) REFERENCES customers_tmp(id);
This avoids full scans for range queries but may cause write hotspots on the date column. Recreating large tables can be operationally difficult.

Solution 3 - Use Secondary Index with Bucket ID
Propose adding virtual bucketing to secondary index:
sqlCREATE INDEX orders_tmp_bucket_idx ON orders_tmp (
  (yb_hash_code(date) % 3) ASC, 
  date ASC
);
Queries with range predicates like < and > can be run without modification.
Queries with Order by would need to UNION ALL across buckets in order to take advantages of efficiencies with bucketid.
sqlSELECT * FROM (
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 0 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 1 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp WHERE yb_hash_code(date) % 3 = 2 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
This reduces hotspots while retaining the original table structure, but requires modifying queries for ORDER BY.

Solution 4 - Modify Table Primary Key to Include Bucket ID
Propose modifying the base table schema to include bucket_id directly in the primary key:
sqlCREATE TABLE orders_tmp_v3 (
   id bigint GENERATED BY DEFAULT AS IDENTITY,
   customer_id INT,
   date DATE,
   bucketid smallint DEFAULT ((random()*10)::int % 3), 
   PRIMARY KEY (bucketid ASC, date ASC, id ASC)
) SPLIT INTO 3 TABLETS;

-- Add foreign key constraint
ALTER TABLE orders_tmp_v3 ADD CONSTRAINT fk_customer 
FOREIGN KEY (customer_id) REFERENCES customers_tmp(id);
Queries with range predicates like < and > can be run without modification.
Queries with Order by would need to UNION ALL across buckets in order to take advantages of efficiencies with bucketid.
sqlSELECT * FROM (
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 0 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 1 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
 UNION ALL
 (SELECT * FROM orders_tmp_v3 WHERE bucketid = 2 AND date > '2024-01-15' ORDER BY date ASC LIMIT 3)
) AS combined
ORDER BY date ASC LIMIT 3;
This reduces hotspots but requires full table rebuild and query rewrites.

Additional Optimization Note:
I also noticed that your join between orders_tmp and products_tmp uses o.id = p.id, which seems unusual. Typically, orders would reference products via a product_id field. You may want to verify this join condition is correct, as it's currently joining on primary keys which may not represent the intended relationship.

Conclusion:
Summarize the trade-offs:

Secondary indexes are simplest but may introduce write overhead and hotspots.
Bucketed indexes reduce hotspots but complicate ORDER BY queries.
Repartitioning tables is ideal for pure range workloads but requires downtime or ETL reload.

For your specific use case, I'd recommend starting with Solution 1 (adding a secondary ASC index on the date column) as it requires minimal changes and will immediately improve performance for date range queries. Monitor for any write hotspots if your date inserts are sequential, and consider the bucketed approaches if hotspots become an issue.
==============================
